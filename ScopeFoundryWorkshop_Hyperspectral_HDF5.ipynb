{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MolecularFoundry/crucible-analysis-notebooks/blob/main/ScopeFoundryWorkshop_Hyperspectral_HDF5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# HDF5 Exploration and Plotting\n",
        "The first section of this notebook is designed to explore and parse an HDF5 file generated by Scope Foundry to understand how they are formatted and then generate a plot of the data.\n",
        "\n",
        "The second half of the notebook is designed specifically to analyze hyperspec_picam_mcl datasets from the hip_microscope confocal optical microscope in the Imaging Facility at the Molecular Foundry. The principles and code in this notebook can also be used to analyze other hyperspectral datasets, with some minor changes to loading of the spec_map, h_array,v_array, and wls data arrays.\n"
      ],
      "metadata": {
        "id": "OfmDitnj2v58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial Setup"
      ],
      "metadata": {
        "id": "uSyup4JH5Tv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For the default Google CoLab python enivronment,\n",
        "# we need to install required packages that are not included by\n",
        "# default. Note this step takes ~30seconds\n",
        "# If this fails, remove the \"> /dev/null\" and try again to see the errors\n",
        "!pip install jupyter_bokeh  > /dev/null"
      ],
      "metadata": {
        "id": "tiC5a0qd3NBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For Google Colab, in order to access datasets store on Google Drive,\n",
        "# we must mount the drives on the filesystem. This will ask for your\n",
        "# permission to share your Google Drive with this notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JSdPdq-H4VSb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To use interactive widgets in CoLab\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "PnRevoUU5FNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Required imports\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import holoviews as hv\n",
        "hv.extension('bokeh')\n"
      ],
      "metadata": {
        "id": "gQnISkgP41rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Edit the location of the dataset you want to analyze (you can copy and paste from the output above)\n",
        "file_path = \"/content/drive/MyDrive/User Meeting/demo_data/0sdazahr0nxh300075jj73j2kg/240119_144139_hyperspec_picam_mcl.h5\"\n",
        "#file_path = \"/content/drive/MyDrive/240119_144139_hyperspec_picam_mcl.h5\""
      ],
      "metadata": {
        "id": "aefHx0J-G5GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Navigating the HDF5 file"
      ],
      "metadata": {
        "id": "5-J2M3jhc2g5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Opening the file\n",
        "with h5py.File(file_path, 'r') as f:\n",
        "  # groups within the file object\n",
        "  print(f.keys())\n",
        "\n",
        "  # attributes of the file object (the file object is the \"root group\")\n",
        "  print(f.attrs.keys())\n",
        "\n",
        "  # every group has a name (the name is the key)\n",
        "  for group_name in f:\n",
        "    print(group_name)"
      ],
      "metadata": {
        "id": "i_dnPcsAdPqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The App Group\n",
        "\n",
        "with h5py.File(file_path, 'r') as f:\n",
        "  app = f['app']\n",
        "\n",
        "  # groups within the app group\n",
        "  print(app.keys())\n",
        "\n",
        "  # attributes of the app group\n",
        "  print(app.attrs.keys())\n",
        "\n",
        "  # print the settings group attributes for the app\n",
        "  [print(k,v) for k,v in list(app['settings'].attrs.items())]"
      ],
      "metadata": {
        "id": "Dto3vzoVdYsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HJ2MvL52pFbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Hardware Group\n",
        "\n",
        "with h5py.File(file_path, 'r') as f:\n",
        "  hw = f['hardware']\n",
        "\n",
        "  # groups within the hw group\n",
        "  print(hw.keys())\n",
        "\n",
        "  # attributes of the hw group\n",
        "  print(hw.attrs.keys())\n"
      ],
      "metadata": {
        "id": "x5dlEthvddpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore one of the Hardware Groups\n",
        "with h5py.File(file_path, 'r') as f:\n",
        "  hw_key = 'acton_spectrometer'\n",
        "\n",
        "  hw_setting_attributes = f['hardware'][hw_key]['settings'].attrs\n",
        "\n",
        "  for k in list(hw_setting_attributes.keys()):\n",
        "    print(f\"{k}:  {hw_setting_attributes[k]}\")"
      ],
      "metadata": {
        "id": "zkFviBr6gFP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Measurement Group\n",
        "with h5py.File(file_path, 'r') as f:\n",
        "  M = f['measurement']\n",
        "\n",
        "  # groups within the measurement group\n",
        "  print(M.keys())\n",
        "\n",
        "  # attributes of the measurement group\n",
        "  print(M.attrs.keys())\n",
        "\n",
        "  # Look at the measurement sub group\n",
        "  # Note that you can keep extending out key values for groups or use a file system like notation\n",
        "  print(f['measurement']['hyperspec_picam_mcl'].keys())\n",
        "  print(f['measurement/hyperspec_picam_mcl'].keys())\n",
        "\n",
        "  # Each of the values printed is a Dataset Object that can be accessed as a numpy array\n",
        "  arr = np.array(f['measurement/hyperspec_picam_mcl/wls'])\n",
        "  print(arr[0:5])"
      ],
      "metadata": {
        "id": "1iN4s5QtdfoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recursively parsing an Scope Foundry HDF5 to dictionary\n",
        "\n",
        "def parse_h5(h5_path):\n",
        "  d = dict()\n",
        "  def nest_json(k,v, d=d):\n",
        "      keys=k.split(\"/\")\n",
        "      for key in keys:\n",
        "          if key in d.keys():\n",
        "              d = d[key]\n",
        "          else:\n",
        "              d[key] = {}\n",
        "      for eachkey in v.attrs.keys():\n",
        "          d[key][eachkey] = v.attrs[eachkey]\n",
        "\n",
        "  h5file = h5py.File(h5_path, 'r')\n",
        "  h5file.visititems(nest_json)\n",
        "  return(d)\n",
        "\n",
        "h5dict = parse_h5(file_path)\n",
        "print(h5dict.keys())"
      ],
      "metadata": {
        "id": "HH9vUZj_dhwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The value of partial IO\n",
        "\n",
        "import time\n",
        "\n",
        "# Time to read in the whole HDF5 file and extract the wavelength array\n",
        "start_time = time.time()\n",
        "F = h5py.File(file_path, 'r')\n",
        "wls = F['measurement/hyperspec_picam_mcl/wls']\n",
        "F.close()\n",
        "end_time = time.time()\n",
        "print(f\"Loading the whole file to get the wls array took: {round(end_time - start_time, 3)}s\")\n",
        "\n",
        "\n",
        "# Time to extract the wavelength array using partial IO functionality of H5\n",
        "start_time = time.time()\n",
        "with h5py.File(file_path, 'r') as f:\n",
        "  wls = f['measurement/hyperspec_picam_mcl/wls']\n",
        "end_time = time.time()\n",
        "print(f\"Loading the wls array with partial IO took: {round(end_time - start_time, 3)}s\")\n"
      ],
      "metadata": {
        "id": "KZVs4VDKdlRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperspectral Analysis and Plotting"
      ],
      "metadata": {
        "id": "COGa9PGyc_ro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading your Data File for Plotting"
      ],
      "metadata": {
        "id": "o7CvoodV5aLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the parts of the ScopeFoundry HDF5 that you need for plotting\n",
        "with h5py.File(file_path, 'r') as f:\n",
        "    M = f['measurement/hyperspec_picam_mcl']\n",
        "    # 3D array of spectra (2D spatial dimensions)\n",
        "    spec_map = np.array(M['spec_map'])[0]\n",
        "    # positions of data points in um along x (horizontal) axis\n",
        "    h_array = np.array(M['h_array'])\n",
        "    # positions of data points in um along y (vertical) axis\n",
        "    v_array = np.array(M['v_array'])\n",
        "    # wavelengths of spectral values\n",
        "    wls = np.array(M['wls'])\n",
        "    # bounds of image\n",
        "    imshow_extent = np.array(M['imshow_extent'])"
      ],
      "metadata": {
        "id": "VPWhpha05yQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Intensity Maps and Spectra\n"
      ],
      "metadata": {
        "id": "ph4iS6ZB-J7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = spec_map.sum(axis=-1)\n",
        "plt.figure()\n",
        "vmin,vmax = np.percentile(img, [1,99])\n",
        "plt.imshow(img, origin='lower',vmin=vmin,vmax=vmax)\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "r5ssXl0o-rZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_spec = spec_map.mean(axis=(0,1))\n",
        "plt.figure()\n",
        "plt.plot(wls, avg_spec)\n",
        "plt.xlabel(\"wls\")\n",
        "plt.ylabel(\"intensity\")"
      ],
      "metadata": {
        "id": "a_nMlGq4_OCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Band Pass Images"
      ],
      "metadata": {
        "id": "nb5if0kv-sTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wl0 = 500 # Starting wavelength in nm\n",
        "wl1 = 600 # Ending wavelength in nm\n",
        "\n",
        "kk0,kk1 = np.searchsorted(wls, (wl0,wl1))\n",
        "bandpass_image = spec_map[:,:,kk0:kk1].sum(axis=-1)\n",
        "plt.figure()\n",
        "\n",
        "vmin,vmax = np.percentile(bandpass_image, [1,99])\n",
        "plt.imshow(bandpass_image, origin='lower',vmin=vmin,vmax=vmax, cmap=plt.cm.magma)\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "0i4uGKug-SJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interactive Data Exploration"
      ],
      "metadata": {
        "id": "izJ0qi9T_qgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame()\n",
        "\n",
        "Ny, Nx, Nspec = spec_map.shape\n",
        "X,Y = np.meshgrid(h_array,v_array)\n",
        "II,JJ = np.meshgrid(np.arange(Nx), np.arange(Ny))\n",
        "II.reshape(-1).shape\n",
        "all_spectra = spec_map.reshape(-1,Nspec)\n",
        "df['x']  = X.reshape(-1)\n",
        "df['y']  = Y.reshape(-1)\n",
        "df['ii'] = II.reshape(-1)\n",
        "df['jj'] = JJ.reshape(-1)\n",
        "df['total_intensity'] = spec_map.sum(axis=-1).reshape(-1)\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "672xRNkfV-MX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hv.extension('bokeh')\n",
        "from holoviews import opts\n",
        "from holoviews.streams import Selection1D\n",
        "\n",
        "df2 = df[['x','y']]\n",
        "\n",
        "opts.defaults(opts.Points(tools=['box_select', 'lasso_select']))\n",
        "\n",
        "point_map = hv.Points(df)\n",
        "\n",
        "wlsmin = range(0,int(max(wls)-1))\n",
        "wlsmax = range(1, int(max(wls)))\n",
        "kdims = [hv.Dimension('wlsmin', label = 'Min. Wavelength', range = (int(min(wls)),int(max(wls)-1)), default=int(min(wls))),\n",
        "         hv.Dimension('wlsmax', label = 'Max Wavelength', range = (int(min(wls)+1), int(max(wls))), default=int(max(wls)))]\n",
        "\n",
        "index_stream = Selection1D(source=point_map)\n",
        "print(index_stream)\n",
        "\n",
        "def spec_map_bandpass_hvImage(wlsmin,wlsmax):\n",
        "  kk0,kk1 = np.searchsorted(wls, [wlsmin, wlsmax])\n",
        "  im = spec_map[:,:,kk0:kk1].mean(axis=-1)\n",
        "  hvIm = hv.Image((h_array,v_array,im))\n",
        "  hvIm.opts(aspect = \"equal\", cmap = \"plasma\")\n",
        "  return hvIm\n",
        "\n",
        "\n",
        "def selected_info(index):\n",
        "    selected = point_map.iloc[index]\n",
        "    #print(len(index), selected)\n",
        "    #print(df.iloc[index])\n",
        "    #specs = features[index] # N x Nspec\n",
        "    #mean_spec = specs.mean(axis=0)\n",
        "    #if index:\n",
        "    #    label = 'Mean x, y: {}, {}'.format( tuple(selected.array().mean(axis=0)))\n",
        "    #else:\n",
        "    #label = 'No selection'\n",
        "    #return selected.relabel(label).opts(color='red')\n",
        "    return selected\n",
        "\n",
        "selected_box = hv.DynamicMap(selected_info,\n",
        "                              streams=[index_stream])\n",
        "\n",
        "def select_spec(index):\n",
        "  #print(index)\n",
        "  if index == []:\n",
        "    index = [0,]\n",
        "  specs = all_spectra[index] # N x Nspec\n",
        "  #print(specs.shape)\n",
        "  mean_spec = specs.mean(axis=0)\n",
        "  return hv.Curve(pd.DataFrame({'wls':wls,'intensity':mean_spec}))\n",
        "\n",
        "spec_dmap = hv.DynamicMap(select_spec, streams=[index_stream])\n",
        "\n",
        "dyn_specmap = hv.DynamicMap(spec_map_bandpass_hvImage, kdims=kdims)\n",
        "\n",
        "\n",
        "\n",
        "lo = ( dyn_specmap * point_map)   + spec_dmap\n",
        "display(lo)\n"
      ],
      "metadata": {
        "id": "cWb-1mM-_unO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use selected spectra\n",
        "selected_spec_indexes = index_stream.contents['index']\n",
        "selected_specs = all_spectra[selected_spec_indexes]\n",
        "print(f\"Selected {len(selected_spec_indexes)} spectra\")\n",
        "spec_rows = df.iloc[selected_spec_indexes]\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(spec_map.sum(axis=-1),origin='lower',extent=imshow_extent)\n",
        "plt.scatter(spec_rows['x'], spec_rows['y'], color='w', marker='x')\n",
        "plt.gca().set_aspect(1)\n",
        "plt.figure()\n",
        "for i in selected_spec_indexes:\n",
        "  row = df.iloc[i]\n",
        "  plt.plot(all_spectra[i], label=f\"{i} [{row['x']}, {row['y']}]\")\n",
        "plt.plot(selected_specs.mean(axis=0), label='mean spectrum')\n",
        "\n",
        "if len(selected_spec_indexes) < 15:\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "i1GuP4Gte0TZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uF9GIdhCg7nI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}