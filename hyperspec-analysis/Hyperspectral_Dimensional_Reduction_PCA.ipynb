{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MolecularFoundry/crucible-analysis-notebooks/blob/main/hyperspec-analysis/Hyperspectral_Dimensional_Reduction_PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Hyperspectral Confocal Microscopy  Dimensional Reduction with PCA\n",
        "\n",
        "This notebook is designed to analyze `hyperspec_picam_mcl` datasets from the `hip_microscope` confocal optical microscope in the Imaging Facility at the Molecular Foundry. The principles and code in this notebook can also be used to analyze other hyperspectral datasets, with some minor changes to loading of the `spec_map`, `h_array`,`v_arra`y, and `wls` data arrays.\n",
        "\n"
      ],
      "metadata": {
        "id": "zuCr4cBfjx5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial Setup"
      ],
      "metadata": {
        "id": "kEc5oHd62JA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For Google CoLab, in order to access datasets store on Google Drive,\n",
        "# we must mount the drives on the filesystem. This will ask for your\n",
        "# permission to share your Google Drive with this notebook\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "n5lJ4MlDkEh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To use interactive widgets in CoLab\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "ni6oJFW1kIcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Required imports\n",
        "import h5py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import holoviews as hv\n",
        "import glob\n",
        "hv.extension('bokeh')\n"
      ],
      "metadata": {
        "id": "8Xzi7WFykSYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading your Data File"
      ],
      "metadata": {
        "id": "XOX_UqYmkZ5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = \"MFP09238\""
      ],
      "metadata": {
        "id": "EKZ2xJBVkabp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_options = glob.glob(f\"/content/drive/Shareddrives/{project_id}/Datasets/*/*.h5\")\n",
        "\n",
        "print(\"Datasets found at the path above are: \")\n",
        "for ds in dataset_options:\n",
        "  print(ds)"
      ],
      "metadata": {
        "id": "O2UVzB2sFa1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Edit the location of the dataset you want to analyze (you can copy and paste from the output above)\n",
        "\n",
        "file_path = \"\""
      ],
      "metadata": {
        "id": "NFkYcK0PFa7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ScopeFoundry HDF5\n",
        "with h5py.File(file_path, 'r') as f:\n",
        "    M = f['measurement/hyperspec_picam_mcl']\n",
        "    # 3D array of spectra (2D spatial dimensions)\n",
        "    spec_map = np.array(M['spec_map'])[0]\n",
        "    # positions of data points in um along x (horizontal) axis\n",
        "    h_array = np.array(M['h_array'])\n",
        "    # positions of data points in um along y (vertical) axis\n",
        "    v_array = np.array(M['v_array'])\n",
        "    # wavelengths of spectral values\n",
        "    wls = np.array(M['wls'])\n",
        "    # bounds of image\n",
        "    imshow_extent = np.array(M['imshow_extent'])"
      ],
      "metadata": {
        "id": "RpY2qATlkcyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store spectra as a flat list and table\n",
        "df = pd.DataFrame()\n",
        "\n",
        "Ny, Nx, Nspec = spec_map.shape\n",
        "X,Y = np.meshgrid(h_array,v_array)\n",
        "II,JJ = np.meshgrid(np.arange(Nx), np.arange(Ny))\n",
        "II.reshape(-1).shape\n",
        "all_spectra = spec_map.reshape(-1,Nspec)\n",
        "df['x']  = X.reshape(-1)\n",
        "df['y']  = Y.reshape(-1)\n",
        "df['ii'] = II.reshape(-1)\n",
        "df['jj'] = JJ.reshape(-1)\n",
        "df['total_intensity'] = spec_map.sum(axis=-1).reshape(-1)\n",
        "\n",
        "display(\"all_spectra:\",all_spectra)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Pm7OELMqkfBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot Image and Spectra"
      ],
      "metadata": {
        "id": "UgZwnD-0lALj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = spec_map.sum(axis=-1)\n",
        "plt.figure()\n",
        "vmin,vmax = np.percentile(img, [1,99])\n",
        "plt.imshow(img, extent=imshow_extent, origin='lower',vmin=vmin,vmax=vmax)\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "arHjO3_flDXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_spec = spec_map.mean(axis=(0,1))\n",
        "plt.figure()\n",
        "plt.plot(wls, avg_spec)\n",
        "plt.xlabel(\"wls\")\n",
        "plt.ylabel(\"intensity\")"
      ],
      "metadata": {
        "id": "qKMX0zI3lDuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yxLHVhOmlUQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Principal Component Analysis"
      ],
      "metadata": {
        "id": "hTzpGKb2oT7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Scikit Learn PCA\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "NdOZ30q5oZEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hv.extension('bokeh')\n",
        "# Peform PCA on data\n",
        "scaledf = StandardScaler().fit_transform(all_spectra)\n",
        "pca1 = PCA(random_state = 833)\n",
        "pca1.fit(scaledf)\n",
        "pca_var_df = pd.DataFrame({\"component\":range(0,pca1.n_components_ ), \"exp_var_ratio\":pca1.explained_variance_ratio_})\n",
        "# Plot the Explain Variance ratio of the first 20 PCA componenents\n",
        "pca_var = hv.Scatter(pca_var_df.iloc[0:20, :], kdims = [\"component\"], vdims = ['exp_var_ratio'])\n",
        "pca_var.opts(size = 6)\n",
        "display(pca_var)"
      ],
      "metadata": {
        "id": "tyfzBZV_oZgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute component weights on all spectra\n",
        "N_components = 10\n",
        "pca_transform = pca1.transform(scaledf)\n",
        "pcadf = pd.DataFrame(data = pca_transform[:,:N_components], columns = [f'PC{str(int(x))}' for x in range(0,N_components)])\n",
        "\n",
        "spectra_df_with_pca = pd.concat([df,pcadf],axis=1, join=\"inner\")\n",
        "display(spectra_df_with_pca)"
      ],
      "metadata": {
        "id": "iVwS26UuokV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the components\n",
        "N_components = 3\n",
        "for i in range(N_components):\n",
        "  plt.plot(wls, pca1.components_[i,:], label=f\"PCA Component {i}\")\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "iMXMc6Seyw1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA component correlation plots\n",
        "plt.figure(figsize=(8,8))\n",
        "for i in range(4):\n",
        "  for j in range(4):\n",
        "      plt.subplot(4,4,4*j+i+1)\n",
        "      plt.title( f\"PC{i} vs PC{j}\")\n",
        "      plt.scatter(spectra_df_with_pca[f'PC{i}'], spectra_df_with_pca[f'PC{j}'], marker='.')\n",
        "      plt.tick_params(left = False, right = False , labelleft = False ,\n",
        "                      labelbottom = False, bottom = False)"
      ],
      "metadata": {
        "id": "swFuxhcVrUV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA component ratio images\n",
        "Ny, Nx, Nspec = spec_map.shape\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "for i in range(4):\n",
        "  for j in range(4):\n",
        "      plt.subplot(4,4,4*j+i+1)\n",
        "      plt.title( f\"PC{i} vs PC{j}\")\n",
        "\n",
        "      PCi_map = np.array(spectra_df_with_pca[f'PC{i}']).reshape(Ny,Nx)\n",
        "      PCj_map = np.array(spectra_df_with_pca[f'PC{j}']).reshape(Ny,Nx)\n",
        "\n",
        "      ratio_map = PCj_map/PCi_map\n",
        "      vmin,vmax = np.percentile(ratio_map, [5,95])\n",
        "      plt.imshow(ratio_map, origin='lower', vmin=vmin,vmax=vmax)\n",
        "      plt.tick_params(left = False, right = False , labelleft = False ,\n",
        "                      labelbottom = False, bottom = False)"
      ],
      "metadata": {
        "id": "gireynzRyvz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rmpSrDBq0DKJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}