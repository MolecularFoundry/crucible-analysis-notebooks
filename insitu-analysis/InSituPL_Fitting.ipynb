{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TimKo90/crucible-analysis-notebooks/blob/main/insitu-analysis/InSituPL_Fitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94e1fcd7-9c32-401a-b3c5-e022cc416d7e",
      "metadata": {
        "id": "94e1fcd7-9c32-401a-b3c5-e022cc416d7e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import ticker\n",
        "from scipy.optimize import curve_fit\n",
        "from scipy.signal import savgol_filter\n",
        "from scipy import signal\n",
        "import scipy.integrate as integrate\n",
        "from scipy.interpolate import interp1d\n",
        "import copy\n",
        "import os\n",
        "import traceback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "416da37a-5cd6-4ef9-9c13-1994aaa6b627",
      "metadata": {
        "id": "416da37a-5cd6-4ef9-9c13-1994aaa6b627"
      },
      "outputs": [],
      "source": [
        "# ================Functions=================================================\n",
        "\n",
        "def sum_of_Voigts(x, *params):\n",
        "\n",
        "    if isinstance(x, float):\n",
        "        x = np.array([x])\n",
        "\n",
        "    params = np.array(params)\n",
        "    n = (len(params)-2) // 4\n",
        "\n",
        "    # divide parameters\n",
        "    amps   = params[:n]\n",
        "    mus    = params[n:2*n]\n",
        "    sigmas = params[2*n:3*n]\n",
        "    alphas = params[3*n:4*n]\n",
        "\n",
        "    gaussians  = amps*np.exp(-(x[:, np.newaxis] - mus)**2 / sigmas)\n",
        "    lorentian  = np.log(2) * (2/np.pi)**0.5 * (amps*sigmas / ((x[:, np.newaxis] - mus)**2 + sigmas*np.log(2)))\n",
        "    background = params[-2]*x + params[-1]\n",
        "\n",
        "    return np.dot(gaussians, 1-alphas) + np.dot(lorentian, alphas) + background\n",
        "\n",
        "\n",
        "def background(x, y0, y1):\n",
        "    return y0*x + y1\n",
        "\n",
        "\n",
        "def fWHM_Voigt(x, center, maxValue, params):\n",
        "\n",
        "    x1 = np.linspace(x[0], center, 5001)\n",
        "    x2 = np.linspace(center, x[-1], 5001)\n",
        "\n",
        "    y1 = sum_of_Voigts(x1, *params)\n",
        "    y2 = sum_of_Voigts(x2, *params)\n",
        "\n",
        "    root1 = np.interp(maxValue/2,y1,x1)\n",
        "    root2 = np.interp(maxValue/2,y2[::-1],x2[::-1])\n",
        "\n",
        "    return root2 - root1\n",
        "\n",
        "\n",
        "def find_zero_crossings(dy, threshold):\n",
        "    \"\"\"\n",
        "    Find zero crossings with a threshold.\n",
        "\n",
        "    Args:\n",
        "    dy: numpy array of y-values (typically the first derivative)\n",
        "    threshold: tolerance around zero (default is 1e-6)\n",
        "\n",
        "    Returns:\n",
        "    numpy array of indices where zero crossings occur\n",
        "    \"\"\"\n",
        "    zero_crossings = []\n",
        "    for i in range(1, len(dy)):\n",
        "        if (dy[i-1] < -threshold and dy[i] > threshold) or \\\n",
        "           (dy[i-1] > threshold and dy[i] < -threshold) or \\\n",
        "           (abs(dy[i-1]) <= threshold and abs(dy[i]) <= threshold):\n",
        "            zero_crossings.append(i)\n",
        "    return np.array(zero_crossings)\n",
        "\n",
        "def peakFinder(x, y, t, num, peak_height_threshold):\n",
        "    smoothing_window=11\n",
        "    poly_order=5\n",
        "\n",
        "    # Assuming x and y are your original data points\n",
        "    x_original = x\n",
        "    y_original = y  # Your original y values\n",
        "\n",
        "    # Create an interpolation function\n",
        "    f = interp1d(x_original, y_original, kind='cubic')\n",
        "\n",
        "    # Create new x values for 1000 points\n",
        "    x_new = np.linspace(np.min(x), np.max(x), 1000)\n",
        "\n",
        "    # Interpolate y values\n",
        "    y_interpolated = f(x_new)\n",
        "\n",
        "    # Apply Savitzky-Golay filter to the interpolated data\n",
        "    y_smooth = savgol_filter(y_interpolated, smoothing_window, poly_order)\n",
        "\n",
        "    # Calculate first and second derivatives\n",
        "    dy = np.gradient(y_smooth)\n",
        "    d2y = np.gradient(dy)\n",
        "\n",
        "    # Usage\n",
        "    zero_crossings = find_zero_crossings(dy, threshold=1e-4)\n",
        "\n",
        "    # Check if second derivative is negative at these points (maxima)\n",
        "    peak_candidates = zero_crossings[d2y[zero_crossings] < 0]\n",
        "\n",
        "    # Filter peak candidates based on height\n",
        "    high_peaks = peak_candidates[y_smooth[peak_candidates] > peak_height_threshold]\n",
        "\n",
        "    return x_new[high_peaks]\n",
        "\n",
        "\n",
        "def plFitting(inputDict, df_yCut, df_xCutFit, df_fit, show_every, numGauss, peakLowerTH, peakUpperTH, estPeakWidth, minPeakWidth, maxPeakWidth, name_d, name, PLFits_CenterGuesses, PLFits_Propagate):\n",
        "\n",
        "    estPositions = PLFits_CenterGuesses\n",
        "\n",
        "    frames = range(0, len(df_xCutFit))\n",
        "    frames_to_plot = [i for i in frames if i % show_every == 0]\n",
        "\n",
        "    yVals = np.copy(df_fit)\n",
        "    popt = np.array([[np.nan, np.nan, np.nan, np.nan]*int(numGauss) + [np.nan, np.nan]] * np.shape(df_fit)[1])\n",
        "    peakFWHM = np.array([[np.nan]*int(numGauss)] * np.shape(df_fit)[1])\n",
        "    peakArea = np.array([[np.nan]*int(numGauss)] * np.shape(df_fit)[1])\n",
        "\n",
        "    # The next block is to convert the estimated peak positions and ranges into indexes\n",
        "    idxLowerTH = [0.0]*int(numGauss)\n",
        "    idxUpperTH = [0.0]*int(numGauss)\n",
        "\n",
        "    for i in range(0, int(numGauss)):\n",
        "        idxLowerTH[i] = next(xStart for xStart, valStart in enumerate(df_yCut) if valStart > peakLowerTH[i])\n",
        "        idxUpperTH[i] = next(xEnd for xEnd, valEnd in enumerate(df_yCut) if valEnd > peakUpperTH[i])\n",
        "\n",
        "    firstSpectrum = True\n",
        "    for i in range(0, np.shape(df_fit)[1]):\n",
        "\n",
        "        # get y values\n",
        "        yVals[:, i] = np.where(yVals[:, i] == float('inf'), 5, yVals[:, i])\n",
        "\n",
        "        idx = np.argmax(yVals[0:idxUpperTH[0], i])\n",
        "        yVals[idx, i] = yVals[idx - 1, i]\n",
        "\n",
        "        # find peaks\n",
        "        peak_height_threshold = np.percentile(df_cut, 50)\n",
        "        xPeaks = peakFinder(df_yCut, yVals[:, i], df_xCutFit, i, peak_height_threshold)\n",
        "\n",
        "        # no peak, skip\n",
        "        if len(xPeaks) == 0:\n",
        "            print(f\"No peak found at t = {df_xCutFit[i]} s.\")\n",
        "            continue\n",
        "\n",
        "        peaks = np.empty(len(xPeaks), dtype=int)\n",
        "        for ii in range(0, len(xPeaks)):\n",
        "            peaks[ii] = int(np.abs(df_yCut - xPeaks[ii]).argmin())\n",
        "        numPeaks = len(peaks)\n",
        "\n",
        "        # array initialization\n",
        "        estAmplitudes = [0.0]*int(numGauss)\n",
        "        minAmplitudes = [0.0]*int(numGauss)\n",
        "        maxAmplitudes = [0.0]*int(numGauss)\n",
        "        estAlphas = [0.5]*int(numGauss)\n",
        "        minAlphas = [0.0]*int(numGauss)\n",
        "        maxAlphas = [1.0]*int(numGauss)\n",
        "        minLinBkg = -1000.0\n",
        "        estLinBkg = yVals[-1,i] - yVals[0,i]\n",
        "        maxLinBkg = 1000.0\n",
        "        minConstBkg = np.min(yVals[:,i])-100\n",
        "        estConstBkg = np.min(yVals[:,i])\n",
        "        maxConstBkg = np.max(yVals[:,i])\n",
        "\n",
        "        if firstSpectrum:\n",
        "            firstSpectrum = False\n",
        "            firstFitIdx = i\n",
        "\n",
        "            # find initial parameters and bounds for peak amplitudes, having free peaks start more prominent than propagating ones\n",
        "            for ii in range(0,int(numGauss)):\n",
        "                if float(PLFits_Propagate[ii]):\n",
        "                    estAmplitudes[ii] = max(yVals[idxLowerTH[ii]:idxUpperTH[ii], i]) / 5\n",
        "                    minAmplitudes[ii] = 0\n",
        "                    maxAmplitudes[ii] = max(yVals[idxLowerTH[ii]:idxUpperTH[ii], i]) / 1.5\n",
        "                else:\n",
        "                    estAmplitudes[ii] = max(yVals[idxLowerTH[ii]:idxUpperTH[ii], i])\n",
        "                    minAmplitudes[ii] = estAmplitudes[ii] / 10\n",
        "                    maxAmplitudes[ii] = np.inf\n",
        "\n",
        "            # collecting fit parameters\n",
        "            estParams = estAmplitudes + estPositions + estPeakWidth + estAlphas + [estLinBkg, estConstBkg]\n",
        "            lowerBounds = minAmplitudes + peakLowerTH + minPeakWidth + minAlphas + [minLinBkg, minConstBkg]\n",
        "            upperBounds = maxAmplitudes + peakUpperTH + maxPeakWidth + maxAlphas + [maxLinBkg, maxConstBkg]\n",
        "\n",
        "        else:\n",
        "            # update initial parameters and bounds. Propagating peaks have their position and width linked to the first one\n",
        "            for ii in range(0,int(numGauss)):\n",
        "\n",
        "                if float(PLFits_Propagate[ii]):\n",
        "                    estAmplitudes[ii] = max(yVals[idxLowerTH[ii]:idxUpperTH[ii], i]) / 10\n",
        "                    minAmplitudes[ii] = 0\n",
        "                    maxAmplitudes[ii] = np.inf\n",
        "                    estPositions[ii] = popt[firstFitIdx,int(numGauss)+ii]\n",
        "                    peakLowerTH[ii] = estPositions[ii] * 0.999\n",
        "                    peakUpperTH[ii] = estPositions[ii] * 1.001\n",
        "                    estPeakWidth[ii] = popt[firstFitIdx][2*int(numGauss)+ii]\n",
        "                    minPeakWidth[ii] = estPeakWidth[ii] / 1.01\n",
        "                    maxPeakWidth[ii] = estPeakWidth[ii] * 1.01\n",
        "\n",
        "                else:\n",
        "                    estAmplitudes[ii] = max(yVals[idxLowerTH[ii]:idxUpperTH[ii], i])\n",
        "                    minAmplitudes[ii] = 0\n",
        "                    maxAmplitudes[ii] = np.inf\n",
        "\n",
        "            # collecting fit parameters\n",
        "            estParams   = estAmplitudes + estPositions + estPeakWidth + estAlphas + [estLinBkg, estConstBkg]\n",
        "            lowerBounds = minAmplitudes + peakLowerTH + minPeakWidth + minAlphas + [minLinBkg, minConstBkg]\n",
        "            upperBounds = maxAmplitudes + peakUpperTH + maxPeakWidth + maxAlphas + [maxLinBkg, maxConstBkg]\n",
        "\n",
        "        # try fitting\n",
        "        try:\n",
        "            popt[i], pcov = curve_fit(sum_of_Voigts,\n",
        "                                   df_yCut,\n",
        "                                   yVals[:, i],\n",
        "                                   p0     = estParams,\n",
        "                                   bounds = (lowerBounds, upperBounds)\n",
        "                                   )\n",
        "\n",
        "\n",
        "        except Exception:\n",
        "            print(f\"The spectrum at t = {df_xCutFit[i]} s was not fitted.\")\n",
        "            # traceback.print_exc()\n",
        "            pass\n",
        "\n",
        "        for ii in range(0,int(numGauss)):\n",
        "            parameters = [popt[i,ii], popt[i,int(numGauss)+ii], popt[i,2*int(numGauss)+ii], popt[i,3*int(numGauss)+ii], 0, 0]\n",
        "            peakFWHM[i,ii] = fWHM_Voigt(df_yCut, popt[i,int(numGauss)+ii], sum_of_Voigts(popt[i,int(numGauss)+ii], *parameters), parameters)\n",
        "            peakArea[i,ii] = integrate.quad(lambda x: sum_of_Voigts(x, *parameters), -np.inf,np.inf)[0]\n",
        "\n",
        "        # plotting fit results for pre-selected frames\n",
        "        if i in frames_to_plot:\n",
        "\n",
        "            plt.figure(figsize=(6, 5))\n",
        "            plt.plot(df_yCut, yVals[:, i], 'o', label='data')\n",
        "            plt.plot(df_yCut, sum_of_Voigts(df_yCut, *popt[i,:]), 'r-', label='fit')\n",
        "\n",
        "            for ii in range(0, int(numGauss)):\n",
        "                plt.plot(df_yCut, sum_of_Voigts(df_yCut, *[popt[i,ii], popt[i,int(numGauss)+ii], popt[i,2*int(numGauss)+ii], popt[i,3*int(numGauss)+ii], 0, 0]), '--', label='Peak ' + str(ii+1))\n",
        "\n",
        "            plt.plot(df_yCut, background(df_yCut, *[popt[i,-2], popt[i,-1]]), 'k--', label='Background')\n",
        "            plt.legend()\n",
        "            plt.xlabel('Energy (eV)')\n",
        "            plt.ylabel('Intensity (a.u.)')\n",
        "            plt.title('Time: ' + str(df_xCutFit[i]))\n",
        "            plt.savefig(os.path.join(name + '/fits/', str(name_d) + '_PL-fit_' + str(int(df_xCutFit[i])) + '_s.png'), format = 'png')\n",
        "            plt.show(block=False)\n",
        "            plt.pause(1)\n",
        "\n",
        "            if inputDict['logplots']:\n",
        "                plt.figure(figsize=(6, 5))\n",
        "                plt.plot(df_yCut, np.log(yVals[:, i]), 'o', label='data')\n",
        "                plt.plot(df_yCut, np.log(sum_of_Voigts(df_yCut, *popt[i,:])), 'r-', label='fit')\n",
        "                plt.legend()\n",
        "                plt.xlabel('Energy (eV)')\n",
        "                plt.ylabel('Log-Intensity (a.u.)')\n",
        "                plt.title('Time: ' + str(df_xCutFit[i]))\n",
        "                plt.savefig(os.path.join(name + '/fits/', str(name_d) + '_PL-fit_Log_' + str(int(df_xCutFit[i])) + '_s.png'), format = 'png')\n",
        "                plt.show(block=False)\n",
        "                plt.pause(1)\n",
        "\n",
        "    # Plotting the time-evolution of the peak-positions and intensities\n",
        "    for i in range(0, int(numGauss)):\n",
        "        fig, ax1 = plt.subplots(figsize=(6, 5))\n",
        "        plot1, = ax1.plot(df_xCutFit, popt[:,int(numGauss)+i], label = 'Peak Position')\n",
        "        ax2 = ax1.twinx()\n",
        "        plot2, = ax2.plot(df_xCutFit, popt[:,i], 'g', label = 'Peak Intensity')\n",
        "        ax1.set_xlabel('Time (s)')\n",
        "        ax1.set_ylabel(r'PL Position (eV)')\n",
        "        ax2.set_ylabel(r'PL Intensity (a.u.)')\n",
        "        # Create your ticker object with M ticks\n",
        "        yticks = ticker.MaxNLocator(5)\n",
        "        ax1.yaxis.set_major_locator(yticks)\n",
        "        fig.suptitle('Fit Results Peak ' + str(i+1) + ' ' + name_d, fontsize=14)\n",
        "        fig.legend()\n",
        "\n",
        "    # collecting the fit results in a dataframe\n",
        "    dfPeaks = pd.DataFrame()\n",
        "    dfPeaks['Fit-Time_' + name_d] = df_xCutFit\n",
        "    for i in range(0,int(numGauss)):\n",
        "        colPos = 'Peak' + str(i+1) + 'Pos_' + name_d\n",
        "        colArea = 'Peak' + str(i+1) + 'Area_' + name_d\n",
        "        colFWHM = 'Peak' + str(i+1) + 'FWHM_' + name_d\n",
        "        colAlphas = 'Peak' + str(i+1) + 'Alpha_' + name_d\n",
        "        data = np.array([peakArea[:,i], popt[:,int(numGauss)+i], peakFWHM[:,i], popt[:,3*int(numGauss)+i]])\n",
        "        dfTemp = pd.DataFrame(\n",
        "            data.T,\n",
        "            columns=[colArea, colPos, colFWHM, colAlphas])\n",
        "        dfPeaks = pd.concat([dfPeaks, dfTemp], axis=1)\n",
        "    dfPeaks = dfPeaks.fillna('nan')\n",
        "\n",
        "    return dfPeaks\n",
        "\n",
        "\n",
        "def plFits(inputDict, energyPL, timePL, intPL, sampleName, savePath, numGauss,\n",
        "           PLFits_CenterGuesses = [\"list of length num gauss containing the user's Initial guess for Peak position (in eV) as a float\"],\n",
        "           PLFits_CenterFixed = [\"list of True/False will the center be fixed\"],\n",
        "           PLFits_Propagate=['list of True/False for propagate']):\n",
        "\n",
        "    # Fit-parameters: Set the lower and upper limits as well as the estimated position of each peak (in nm).\n",
        "    # From left to right, update as many integers as needed but keep the length of arrays at 5; extra values are ignored.\n",
        "    peakLowerTH = [0.0]*int(numGauss)\n",
        "    peakUpperTH = [0.0]*int(numGauss)\n",
        "    estPeakWidth = [0.0] *int(numGauss)\n",
        "    minPeakWidth = [0.0] *int(numGauss)\n",
        "    maxPeakWidth = [0.0] *int(numGauss)\n",
        "\n",
        "\n",
        "    for i in range(0, int(numGauss)):\n",
        "\n",
        "        if PLFits_CenterFixed[i] is True:\n",
        "            peakLowerTH[i] = float(PLFits_CenterGuesses[i]) - 0.005\n",
        "            peakUpperTH[i] = float(PLFits_CenterGuesses[i]) + 0.005\n",
        "            estPeakWidth[i] = (0.1/1.665)**2\n",
        "            minPeakWidth[i] = (0.0/1.665)**2\n",
        "            maxPeakWidth[i] = (0.5/1.665)**2\n",
        "        else:\n",
        "            peakLowerTH[i] = energyPL[0]\n",
        "            peakUpperTH[i] = energyPL[-2]\n",
        "            estPeakWidth[i] = (0.1/1.665)**2\n",
        "            minPeakWidth[i] = (0/1.665)**2\n",
        "            maxPeakWidth[i] = (1/1.665)**2\n",
        "\n",
        "    show_every = int(len(timePL)/10)     # shows every tenth frame with fit\n",
        "\n",
        "    df_fitResults = plFitting(inputDict, energyPL, timePL, intPL, show_every, numGauss, peakLowerTH, peakUpperTH, estPeakWidth, minPeakWidth, maxPeakWidth, sampleName, savePath, PLFits_CenterGuesses, PLFits_Propagate)\n",
        "\n",
        "    return df_fitResults\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount your google drives\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ufr9Z_rzw_Bg"
      },
      "id": "ufr9Z_rzw_Bg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ad37f45-6f3f-4004-8f7a-191086e00bd4",
      "metadata": {
        "id": "2ad37f45-6f3f-4004-8f7a-191086e00bd4"
      },
      "outputs": [],
      "source": [
        "inputDict = {\n",
        "               'smoothing' : False,   # Smoothing of the data to reduce noise\n",
        "               'sFactor' : 3,         # Parameter for smoothing with a SavGol-Filter\n",
        "               'energyScale' : True,\n",
        "               'bkgCorr' : False,     # Enable linear background removal. If True, the program will ask for two ranges for the removal. I recommend setting one of them at higher and the other at lower energy compared to the peaks of interest.\n",
        "               'bkgCorrPoly' : 1,     # This parameter determines the order of the polynomial fit used for background correction (0=const, 1=linear, etc.)\n",
        "               'logplots': 0,\n",
        "               }"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb8eb0cc-9e56-47e7-8eb4-1a7190dd73b1",
      "metadata": {
        "id": "bb8eb0cc-9e56-47e7-8eb4-1a7190dd73b1"
      },
      "source": [
        "### Load and View Sample"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = \"MFP08449\"\n",
        "sample_options = glob.glob(f\"/content/drive/Shareddrives/{project_id}/Datasets/*/*_dataframe.csv\")\n",
        "print(\"Samples found at the path above are: \")\n",
        "for s in sample_options:\n",
        "  print(s)"
      ],
      "metadata": {
        "id": "ru1OEqexxa-C"
      },
      "id": "ru1OEqexxa-C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4c5694f-ed76-4e13-956c-184db0dbfb0b",
      "metadata": {
        "id": "a4c5694f-ed76-4e13-956c-184db0dbfb0b"
      },
      "outputs": [],
      "source": [
        "sample_path = \"\" # copy path from output above\n",
        "sample_name = os.path.basename(sample_path).split(\"_dataframe.csv\")[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e189a453-b707-479d-b9ff-f596b1ab6556",
      "metadata": {
        "id": "e189a453-b707-479d-b9ff-f596b1ab6556"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(f\"{sample_path}\", index_col = \"wl\")\n",
        "\n",
        "num_sort = [str(x) for x in sorted([float(x) for x in df.columns])]\n",
        "df = df.reindex(num_sort, axis=1)\n",
        "\n",
        "# load and convert to arrays\n",
        "df_y = np.array(df.index)\n",
        "df_x = np.array([float(x) for x in df.columns])\n",
        "\n",
        "df = df.to_numpy()\n",
        "df = np.where(df <= 0, 0, df)\n",
        "\n",
        "# transition to energy scale of the y axis\n",
        "if inputDict['energyScale'] == True:\n",
        "    df_y = [1240 / i for i in df_y]\n",
        "\n",
        "    # Jacobian transformation for all measured PL values (basically dividing by E^2)\n",
        "    for i in range(np.shape(df)[1]):\n",
        "        df[:, i] = df[:, i] / df_y / df_y\n",
        "\n",
        "    # Mirroring dataframes to prevent sorting issues\n",
        "    df_y = np.flip(df_y)\n",
        "    df = np.flip(df, axis=0)\n",
        "\n",
        "    yAxisLabel = 'Energy (eV)'\n",
        "\n",
        "else:\n",
        "    yAxisLabel = 'Wavelength (nm)'\n",
        "\n",
        "# Simple plot of the data\n",
        "plot_name = f\"{sample_name}_2D_Plot.png\"\n",
        "\n",
        "plt.figure(1)\n",
        "plt.contourf(df_x, df_y, df, 20, cmap=plt.cm.jet)\n",
        "\n",
        "# Make a colorbar for the ContourSet\n",
        "cbar = plt.colorbar()\n",
        "cbar.ax.set_ylabel('Intensity (a.u.)')\n",
        "\n",
        "# adding labels\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel(yAxisLabel)\n",
        "plt.title(plot_name.strip(\".png\"))\n",
        "\n",
        "plt.savefig(plot_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d46ad438-38ce-47ae-9ca1-740e79ffc1df",
      "metadata": {
        "id": "d46ad438-38ce-47ae-9ca1-740e79ffc1df"
      },
      "source": [
        "### (Optional) Run Background Subtraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16e2d423-8ccf-4dee-a683-8bbffc8bfdff",
      "metadata": {
        "id": "16e2d423-8ccf-4dee-a683-8bbffc8bfdff"
      },
      "outputs": [],
      "source": [
        "# define the following in eV or nm ( you can pick a range on either side of the peak )\n",
        "\n",
        "# background correction range 1 start/end value\n",
        "y_bkgStart1 =0\n",
        "y_bkgEnd1 = 1\n",
        "\n",
        "# background correction range 2 start/end value\n",
        "y_bkgStart2 = 3\n",
        "y_bkgEnd2 = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83b2eac8-632e-46a7-8db3-8c1f119d43a6",
      "metadata": {
        "id": "83b2eac8-632e-46a7-8db3-8c1f119d43a6"
      },
      "outputs": [],
      "source": [
        "# run bkgd subtraction\n",
        "l_bkgStart1 = next(xStart for xStart, valStart in enumerate(df_y) if valStart > y_bkgStart1)\n",
        "l_bkgEnd1 = next(xEnd for xEnd, valEnd in enumerate(df_y) if valEnd > y_bkgEnd1) - 1\n",
        "l_bkgStart2 = next(xStart for xStart, valStart in enumerate(df_y) if valStart > y_bkgStart2)\n",
        "l_bkgEnd2 = next(xEnd for xEnd, valEnd in enumerate(df_y) if valEnd > y_bkgEnd2) - 1\n",
        "\n",
        "for i in range(0, len(df_x)):\n",
        "    xVals = np.concatenate([df_y[l_bkgStart1:l_bkgEnd1], df_y[l_bkgStart2:l_bkgEnd2]])\n",
        "    yVals = np.concatenate([df[l_bkgStart1:l_bkgEnd1, i], df[l_bkgStart2:l_bkgEnd2, i]])\n",
        "    coefs = np.polyfit(xVals, yVals, 1)  # The last parameter determines the order of the polynomial fit (0=const)\n",
        "    poly1d_fn = np.poly1d(coefs)\n",
        "    df[:, i] = df[:, i] - poly1d_fn(df_y[:])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb84d7b6-5179-419c-90aa-2fd478a10f04",
      "metadata": {
        "id": "cb84d7b6-5179-419c-90aa-2fd478a10f04"
      },
      "source": [
        "### Plot Region of Interest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8369b8d2-4bfe-4ca7-a2dc-29879df4d8fd",
      "metadata": {
        "id": "8369b8d2-4bfe-4ca7-a2dc-29879df4d8fd"
      },
      "outputs": [],
      "source": [
        "# define the following\n",
        "startTime = 0.0\n",
        "endTime = 90.0\n",
        "\n",
        "# Wavelength/Energy region to be plotted\n",
        "y_start = 1.4\n",
        "y_end = 1.9\n",
        "\n",
        "# Intensity range (replace 'default' with custom range if needed)\n",
        "z_start = 'default'\n",
        "z_end = 'default'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad67d51c-7494-4d4d-a22c-20f922eb3954",
      "metadata": {
        "id": "ad67d51c-7494-4d4d-a22c-20f922eb3954"
      },
      "outputs": [],
      "source": [
        "# run\n",
        "startTime = max(0, startTime)\n",
        "endTime = min(endTime, df_x[-2])\n",
        "y_start = (max(df_y[0], y_start))\n",
        "y_end = min(y_end, df_y[-2])\n",
        "\n",
        "startTimeIdx = next(tStart for tStart, valStart in enumerate(df_x) if valStart > startTime) - 1\n",
        "endTimeIdx = next(tStart for tStart, valStart in enumerate(df_x) if valStart > endTime) + 1\n",
        "l_start = next(xStart for xStart, valStart in enumerate(df_y) if valStart > y_start) - 1\n",
        "l_end = next(xEnd for xEnd, valEnd in enumerate(df_y) if valEnd > y_end) + 1\n",
        "\n",
        "# shortening the wavelength/energy region to interesting region\n",
        "df_cut = df[l_start:l_end, startTimeIdx:endTimeIdx]\n",
        "df_cutFit = df[:, startTimeIdx:endTimeIdx]\n",
        "\n",
        "# same shortening for the Y-axis and X-axis arrays\n",
        "df_yCut = df_y[l_start:l_end]\n",
        "df_xCut = df_x[startTimeIdx:endTimeIdx]\n",
        "df_xCut = df_xCut - startTime\n",
        "\n",
        "if inputDict['smoothing']:\n",
        "    df_cut = savgol_filter(df_cut, inputDict['sFactor'], 0)\n",
        "    df_cutFit = savgol_filter(df_cutFit, inputDict['sFactor'], 0)\n",
        "\n",
        "if z_start == 'default':\n",
        "    z_start = np.min(df_cut)\n",
        "if z_end == 'default':\n",
        "    z_end = np.max(df_cut)\n",
        "\n",
        "# Show the resulting data\n",
        "plt.figure(3)\n",
        "plt.contourf(df_xCut, df_yCut, df_cut, 20, cmap=plt.cm.jet, levels = np.linspace(z_start,z_end,100))\n",
        "# Make a colorbar for the ContourSet\n",
        "cbar = plt.colorbar()\n",
        "cbar.ax.set_ylabel('Intensity (a.u.)')\n",
        "cbar.set_ticks(np.arange(z_start,z_end+1,(z_end-z_start)/10))\n",
        "# adding labels\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel(yAxisLabel)\n",
        "plt.title(str(sample_name) + ' _2D_Plot')\n",
        "plt.pause(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8dd8192-f72f-4091-ba58-62712e9d755f",
      "metadata": {
        "id": "c8dd8192-f72f-4091-ba58-62712e9d755f"
      },
      "source": [
        "### Bin the data\n",
        "sum a certain number (bin_size) of spectra to improve the fitting accuracy at the cost of time resolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ea2b0c5-6ec8-4ca8-8237-f946de53780c",
      "metadata": {
        "id": "9ea2b0c5-6ec8-4ca8-8237-f946de53780c"
      },
      "outputs": [],
      "source": [
        "# define the number of spectra to sum per bin\n",
        "# set to 0 if you don't want to bin\n",
        "bin_size = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "819a2ea4-8955-4684-8791-affbd8fb9754",
      "metadata": {
        "id": "819a2ea4-8955-4684-8791-affbd8fb9754"
      },
      "outputs": [],
      "source": [
        "if bin_size > 0:\n",
        "    df_cutBin = copy.deepcopy(df_cutFit)\n",
        "    df_cutBin = df_cutFit[:, 0:int(df_xCut.shape[0]/bin_size)]\n",
        "    for i in range(0, df_cutBin.shape[1]):\n",
        "        df_cutBin[:,i] = np.sum(df_cutFit[:, bin_size*i:bin_size*i+bin_size], axis=1)\n",
        "    df_fit = df_cutBin\n",
        "    df_xCutFit = df_xCut[::inputDict['binning']][0:df_cutBin.shape[1]]\n",
        "    df_yCut = df_y\n",
        "else:\n",
        "    df_fit = df_cut\n",
        "    df_xCutFit = df_xCut"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbeba5f0-3232-43d5-9c5e-69f8f35e27f0",
      "metadata": {
        "id": "fbeba5f0-3232-43d5-9c5e-69f8f35e27f0"
      },
      "source": [
        "### Fit the Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set the following parameters\n",
        "numGauss = 2\n",
        "PLFits_CenterGuesses = [1.61, 1.70] # for each gaussian you think exists, put a float of the eV/wl at which you think there is a peak\n",
        "PLFits_CenterFixed = [False, False] # for each gaussian, put a value True/False if you think the center is fixed\n",
        "PLFits_Propagate = [False, False] # for each gaussian, put a value True/False for propagate"
      ],
      "metadata": {
        "id": "mT4mXTLMFaol"
      },
      "id": "mT4mXTLMFaol",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90bd7518-8b8c-4bb7-b0fb-ce101a4b8567",
      "metadata": {
        "id": "90bd7518-8b8c-4bb7-b0fb-ce101a4b8567"
      },
      "outputs": [],
      "source": [
        "# you can rerun this to restart the fit\n",
        "result_path = os.path.join(os.path.dirname(sample_path), \"ProcessedData\")\n",
        "try:\n",
        "  os.mkdir(result_path)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "df_fitResults = plFits(inputDict, df_yCut, df_xCutFit, df_fit, sample_name, os.path.dirname(sample_path), numGauss, PLFits_CenterGuesses, PLFits_CenterFixed, PLFits_Propagate)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select individual spectra to plot"
      ],
      "metadata": {
        "id": "6caCr-kk5zwD"
      },
      "id": "6caCr-kk5zwD"
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this if you want to extract individual points in time\n",
        "# Add the times (in s) that you'd like to extract to this list\n",
        "spectra = [0, 5, 10, 90]\n",
        "\n",
        "\n",
        "idxToPlot = []\n",
        "for i in range(0,len(spectra)):\n",
        "        idx = next(tStart for tStart, valStart in enumerate(df_xCutFit) if valStart > float(spectra[i]))\n",
        "        idxToPlot.append(idx)"
      ],
      "metadata": {
        "id": "rnQgHA0X9Tr5"
      },
      "id": "rnQgHA0X9Tr5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this if you want to extract all spectra in a specific time range\n",
        "# Add the times (in s) that you'd like to use as range\n",
        "firstSpectrum = 0\n",
        "lastSpectrum = 50\n",
        "\n",
        "\n",
        "idxToPlot = []\n",
        "startSpecIdx = next(tStart for tStart, valStart in enumerate(df_xCutFit) if valStart > float(firstSpectrum))\n",
        "endSpecIdx = next(tEnd for tEnd, valStart in enumerate(df_xCutFit) if valStart > float(lastSpectrum))\n",
        "idxToPlot = range(startTimeIdx, endTimeIdx)"
      ],
      "metadata": {
        "id": "Vtj3o2W091v9"
      },
      "id": "Vtj3o2W091v9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intensityToPlot = []\n",
        "fileName = 'Indv_PL-Spectra'\n",
        "timesToPlot = [df_xCutFit[x] for x in idxToPlot]\n",
        "names = ['{:.2f}'.format(x) for x in timesToPlot]\n",
        "names = [sample_name + str(x) + '_s' for x in names]\n",
        "\n",
        "for i in range(0,len(idxToPlot)):\n",
        "        intensity_tmp = df_fit[:,idxToPlot[i]]\n",
        "        intensityToPlot.append(intensity_tmp)\n",
        "\n",
        "intensityToPlot_array = np.array(intensityToPlot).T\n",
        "\n",
        "dfIndv = pd.DataFrame(intensityToPlot_array, columns=names)\n",
        "dfIndv[sample_name + '_Energy_Spectra'] = df_yCut\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize=(7, 5))\n",
        "\n",
        "if len(timesToPlot) < 10:\n",
        "    for i in range(0,len(timesToPlot)):\n",
        "        plt.plot(df_yCut, intensityToPlot[i], label = ('{:.2f}'.format((df_xCutFit[idxToPlot[i]])) + ' s'))\n",
        "        plt.legend(loc=\"upper right\")\n",
        "else:\n",
        "    norm = plt.Normalize(df_xCutFit[idxToPlot[0]], df_xCutFit[idxToPlot[-1]])\n",
        "    cmap = plt.colormaps.get_cmap('coolwarm')\n",
        "    fig, ax = plt.subplots()\n",
        "    for i in range(len(timesToPlot)):\n",
        "        ax.plot(df_yCut, intensityToPlot[i], c=cmap(norm(df_xCutFit[idxToPlot[i]])))\n",
        "    cbar = fig.colorbar(plt.cm.ScalarMappable(cmap=cmap, norm=norm), label=\"Time (s)\", ax=fig.gca())\n",
        "    cbar.set_ticks(np.linspace(df_xCutFit[idxToPlot[0]], df_xCutFit[idxToPlot[-1]], 11))\n",
        "\n",
        "\n",
        "# adding labels\n",
        "plt.xlabel('Energy (eV)')\n",
        "plt.ylabel('Intensity (a.u.)')\n",
        "plt.title(str(sample_name) + ' ' + fileName)\n",
        "\n",
        "plt.xlim([df_yCut[0], df_yCut[-1]])\n",
        "plt.ylim(bottom=0)\n",
        "plt.savefig(f'{result_path}/{sample_name}_{fileName}.png', dpi=300, bbox_inches=\"tight\")\n",
        "plt.show(block=False)\n",
        "plt.pause(1)"
      ],
      "metadata": {
        "id": "5Qxagyxs3dhl"
      },
      "id": "5Qxagyxs3dhl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c53875df-ea50-411e-a3b8-9f1ef62bab43",
      "metadata": {
        "id": "c53875df-ea50-411e-a3b8-9f1ef62bab43"
      },
      "outputs": [],
      "source": [
        "### Save the Results\n",
        "np.savetxt(f'{result_path}/{sample_name}_2D.csv', df_fit, delimiter=\",\")\n",
        "np.savetxt(f'{result_path}/{sample_name}_time.csv', df_xCutFit, delimiter=\",\", header='Time_' + sample_name, comments='')\n",
        "np.savetxt(f'{result_path}/{sample_name}_energy.csv', df_yCut, delimiter=\",\", header='Energy_' + sample_name, comments='')\n",
        "df_fitResults.to_csv(f\"{result_path}/{sample_name}_PL_FitResults.csv\", index=False)\n",
        "try:\n",
        "  dfIndv.to_csv(f'{result_path}/{sample_name}_Indv_PL-Spectra.csv', index=None)\n",
        "except:\n",
        "  pass"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}